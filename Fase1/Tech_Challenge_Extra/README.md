# Sistema de DetecÃ§Ã£o de Pneumonia em Raios-X

## Tech Challenge EXTRA - Fase 1 | FIAP PÃ³s-Tech IA para Devs

Bem-vindo ao projeto extra do Tech Challenge!

Este projeto usa **VisÃ£o Computacional** e **Redes Neurais Convolucionais (CNN)** para detectar pneumonia em imagens de raios-X do tÃ³rax. Ã‰ um exemplo prÃ¡tico de como a inteligÃªncia artificial pode ajudar profissionais da saÃºde na anÃ¡lise de exames mÃ©dicos.

## O que esse projeto faz?

O sistema analisa imagens de radiografias de tÃ³rax e classifica em duas categorias:
- **NORMAL**: PulmÃµes saudÃ¡veis
- **PNEUMONIA**: PresenÃ§a de pneumonia

Eu usei redes neurais profundas que "aprendem" a reconhecer padrÃµes nas imagens, similar a como um radiologista aprende durante anos de prÃ¡tica - mas de forma automatizada!

### Como funciona?

1. Recebe: Uma imagem de raio-X do tÃ³rax
2. Processa: A CNN analisa a imagem em vÃ¡rias camadas, detectando caracterÃ­sticas
3. Classifica: Retorna se Ã© NORMAL ou PNEUMONIA com um nÃ­vel de confianÃ§a

> **IMPORTANTE**: Este Ã© um projeto acadÃªmico para fins educacionais. Na prÃ¡tica mÃ©dica real, diagnÃ³sticos devem sempre ser realizados por profissionais qualificados. Este sistema serve apenas como ferramenta de apoio Ã  decisÃ£o!

## Dataset

Utilizei o dataset **Chest X-Ray Images (Pneumonia)** do Kaggle:
- **Fonte**: [Kaggle - Paul Mooney](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia)
- **Como obter**: Executar `python src/download_dataset.py` (requer credenciais Kaggle API)
- **Formato**: 5,863 imagens de raios-X em JPEG
- **OrganizaÃ§Ã£o**: Divididas em 3 pastas: train, test, val
- **Classes**: Cada pasta contÃ©m subpastas NORMAL e PNEUMONIA

**DistribuiÃ§Ã£o dos dados:**
- Training: ~5,200 imagens
- Validation: ~16 imagens  
- Test: ~624 imagens

## Estrutura do Projeto

```
Tech_Challenge_Extra/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ chest_xray/                   # Dataset (baixado via script)
â”‚       â”œâ”€â”€ train/
â”‚       â”‚   â”œâ”€â”€ NORMAL/
â”‚       â”‚   â””â”€â”€ PNEUMONIA/
â”‚       â”œâ”€â”€ test/
â”‚       â”‚   â”œâ”€â”€ NORMAL/
â”‚       â”‚   â””â”€â”€ PNEUMONIA/
â”‚       â””â”€â”€ val/
â”‚           â”œâ”€â”€ NORMAL/
â”‚           â””â”€â”€ PNEUMONIA/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_exploracao_dados.ipynb     # AnÃ¡lise exploratÃ³ria
â”‚   â””â”€â”€ 02_treinamento_modelo.ipynb   # Treinamento e avaliaÃ§Ã£o
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ preprocessing.py              # PrÃ©-processamento de imagens
â”‚   â”œâ”€â”€ models.py                     # Arquiteturas CNN
â”‚   â”œâ”€â”€ evaluation.py                 # MÃ©tricas e avaliaÃ§Ã£o
â”‚   â”œâ”€â”€ download_dataset.py           # Script para baixar dados do Kaggle
â”‚   â””â”€â”€ __pycache__/
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ graficos/                     # VisualizaÃ§Ãµes e grÃ¡ficos
â”‚   â”œâ”€â”€ modelos/                      # Modelos treinados (.h5)
â”‚   â”œâ”€â”€ comparacao_modelos.csv        # Resultados consolidados
â”‚   â””â”€â”€ resumo_resultados.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ RELATORIO_TECNICO.md
â””â”€â”€ README.md
```

### Importante sobre o Dataset

âš ï¸ **O dataset NÃƒO vem incluÃ­do no repositÃ³rio** por ser muito grande (~2 GB)
- Use o script `python src/download_dataset.py` para baixar
- Requer credenciais do Kaggle API configuradas
- Veja a seÃ§Ã£o "Como usar" â†’ "Configure o Kaggle API" para instruÃ§Ãµes

## Como usar

### PrÃ©-requisitos
- Python 3.9 ou superior
- GPU (opcional, mas recomendada para treinamento mais rÃ¡pido)
- Conta no Kaggle (para baixar o dataset)

### OpÃ§Ã£o 1: InstalaÃ§Ã£o Local (Windows)

#### 1. Clone o repositÃ³rio
```powershell
git clone https://github.com/theeustassi/postech-iaparadevs.git
cd Tech_Challenge_Extra
```

#### 2. Crie um ambiente virtual
```powershell
python -m venv venv
.\venv\Scripts\Activate.ps1
```

#### 3. Instale as dependÃªncias
```powershell
pip install -r requirements.txt
```

#### 4. Configure o Kaggle API
Baixe suas credenciais do Kaggle:
1. Acesse https://www.kaggle.com/settings
2. Clique em "Create New API Token"
3. Salve o arquivo `kaggle.json` em `~/.kaggle/` (Linux/Mac) ou `C:\Users\<seu_usuario>\.kaggle\` (Windows)

#### 5. Baixe o dataset
```powershell
python src/download_dataset.py
```

#### 6. Execute os notebooks
```powershell
jupyter notebook notebooks/
```

### OpÃ§Ã£o 2: Usando Docker

```powershell
# Build da imagem
docker build -t pneumonia-detector .

# Executar container
docker run -p 8888:8888 -v ${PWD}:/workspace pneumonia-detector
```

## ğŸ§ª Modelos Implementados

### 1. CNN Simples (Baseline)
- Arquitetura customizada com 3-4 camadas convolucionais
- Boa para entender os conceitos bÃ¡sicos
- ~10-20 minutos de treinamento

### 2. Transfer Learning - VGG16
- Modelo prÃ©-treinado no ImageNet
- Fine-tuning nas Ãºltimas camadas
- Melhor precisÃ£o com menos tempo de treinamento

### 3. Transfer Learning - ResNet50
- Arquitetura mais moderna com conexÃµes residuais
- Excelente para datasets mÃ©dicos
- Alto desempenho

## MÃ©tricas de AvaliaÃ§Ã£o

Avaliamos os modelos usando:
- **Accuracy**: PrecisÃ£o geral
- **Precision**: Quantos dos diagnosticados com pneumonia realmente tÃªm
- **Recall (Sensibilidade)**: Quantos casos de pneumonia conseguimos detectar
- **F1-Score**: MÃ©dia harmÃ´nica entre precision e recall
- **Confusion Matrix**: VisualizaÃ§Ã£o de acertos e erros
- **ROC Curve & AUC**: Capacidade de discriminaÃ§Ã£o do modelo

> No contexto mÃ©dico, o **Recall** Ã© crÃ­tico! Ã‰ melhor ter alguns falsos positivos (dizer que tem pneumonia quando nÃ£o tem) do que falsos negativos (nÃ£o detectar uma pneumonia real).

## Resultados Obtidos

Treinei 3 modelos diferentes e obtive os seguintes resultados:

| Modelo | Accuracy | Precision | Recall | F1-Score | AUC-ROC |
|--------|----------|-----------|--------|----------|---------|
| **CNN Simples** | 79.17% | 75.29% | **99.23%** | 85.62% | **0.9538** |
| **VGG16** | 62.50% | 62.50% | 100.00% | 76.92% | 0.6141 |
| **ResNet50** | **87.82%** | **88.67%** | 92.31% | **90.45%** | 0.9296 |

### Modelo Recomendado: **ResNet50**

**Por quÃª?**
- Melhor accuracy geral: 87.82%
- Melhor precision: 88.67% (menos falsos positivos)
- Excelente recall: 92.31% (detecta 92% dos casos de pneumonia)
- Melhor F1-Score: 90.45% (melhor equilÃ­brio)

**CNN Simples tambÃ©m Ã© excelente para:**
- Triagem inicial: Recall de 99.23% (quase nÃ£o perde nenhum caso!)
- Melhor AUC-ROC: 0.9538 (excelente capacidade discriminativa)

**VGG16 teve problemas:**
- Classificou quase tudo como PNEUMONIA
- Precision para NORMAL = 0%
- Necessita ajustes e retreinamento

### Insights Importantes

1. **Transfer Learning funcionou!** ResNet50 (87.82%) >> CNN Simples (79.17%)
2. **Trade-off Precision vs Recall**: CNN tem recall altÃ­ssimo mas mais falsos positivos
3. **Nem sempre mais parÃ¢metros = melhor resultado**: VGG16 (14.8M params) teve pior desempenho
4. **Class weights sÃ£o essenciais** em datasets desbalanceados
5. **Early stopping preveniu overfitting**: modelos pararam automaticamente em ~12 Ã©pocas

Veja anÃ¡lise completa no [RELATORIO_TECNICO.md](RELATORIO_TECNICO.md)!

## Conceitos Aprendidos

Este projeto aborda:
- Processamento de imagens mÃ©dicas
- Redes Neurais Convolucionais (CNN)
- Transfer Learning
- Data Augmentation
- Overfitting e tÃ©cnicas de regularizaÃ§Ã£o
- MÃ©tricas para problemas de classificaÃ§Ã£o desbalanceados
- VisualizaÃ§Ã£o de resultados com Grad-CAM

### Autor
Matheus Tassi Souza - RM367424
