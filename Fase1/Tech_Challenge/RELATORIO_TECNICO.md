# Relatório Técnico - Tech Challenge Fase 1

## Sistema Inteligente de Suporte ao Diagnóstico de Câncer de Mama

---

## 1. Resumo Executivo

Este projeto desenvolveu um sistema de Machine Learning para auxiliar no diagnóstico de câncer de mama, classificando tumores como **malignos** ou **benignos** com base em características extraídas de imagens de aspirado por agulha fina (FNA). O sistema foi desenvolvido utilizando o Wisconsin Breast Cancer Dataset e implementa múltiplos algoritmos de classificação, com foco em métricas adequadas ao contexto médico.

### Resultados Principais
- **Dataset**: 569 amostras com 30 features numéricas
- **Modelos avaliados**: 5 algoritmos diferentes
- **Melhor modelo**: SVM (Support Vector Machine)
- **Performance**: F1-Score de 96.55% no conjunto de teste
- **Interpretabilidade**: Análise SHAP e feature importance implementadas

---

## 2. Introdução

### 2.1 Contexto do Problema

O câncer de mama é uma das principais causas de mortalidade entre mulheres no mundo. O diagnóstico precoce e preciso é fundamental para aumentar as chances de cura e reduzir a necessidade de tratamentos agressivos. 

Atualmente, o processo diagnóstico envolve:
1. Exame clínico inicial
2. Exames de imagem (mamografia, ultrassom)
3. Biópsia com aspirado por agulha fina (FNA)
4. Análise laboratorial das células

### 2.2 Objetivo do Projeto

Desenvolver um sistema de Machine Learning capaz de:
- Classificar tumores como malignos ou benignos
- Fornecer probabilidades de diagnóstico
- Explicar as decisões tomadas pelo modelo
- Servir como ferramenta de suporte à decisão médica

### 2.3 Justificativa

Um sistema automatizado de suporte ao diagnóstico pode:
- **Reduzir o tempo de análise**: Triagem inicial automática
- **Aumentar a precisão**: Segunda opinião automatizada
- **Otimizar recursos**: Priorização de casos complexos
- **Reduzir erros**: Minimizar falsos negativos críticos

---

## 3. Dataset

### 3.1 Descrição do Dataset

**Nome**: Wisconsin Breast Cancer Dataset  
**Fonte**: [UCI Machine Learning Repository via Kaggle](https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data)  
**Criador**: Dr. William H. Wolberg, University of Wisconsin

### 3.2 Características

- **Amostras**: 569 casos (357 benignos, 212 malignos)
- **Features**: 30 características numéricas
- **Classes**: 
  - B (Benigno): 62.7%
  - M (Maligno): 37.3%

### 3.3 Features Extraídas

Para cada núcleo celular, foram calculadas 10 características:

1. **radius** - raio (distância média do centro aos pontos no perímetro)
2. **texture** - textura (desvio padrão dos valores de escala de cinza)
3. **perimeter** - perímetro
4. **area** - área
5. **smoothness** - suavidade (variação local nos comprimentos dos raios)
6. **compactness** - compacidade (perimeter² / area - 1.0)
7. **concavity** - concavidade (severidade das porções côncavas do contorno)
8. **concave points** - pontos côncavos (número de porções côncavas)
9. **symmetry** - simetria
10. **fractal dimension** - dimensão fractal

Para cada característica, foram calculadas:
- **mean** - média
- **standard error** - erro padrão
- **worst** - pior valor (média dos três maiores valores)

Total: 10 características × 3 medidas = 30 features

### 3.4 Análise Exploratória

#### Distribuição das Classes
- Dataset levemente desbalanceado (62.7% benigno, 37.3% maligno)
- Desbalanceamento moderado, não requer técnicas especiais de balanceamento
- Estratificação utilizada na divisão dos dados

#### Correlações Principais
Features mais correlacionadas com o diagnóstico:
1. **concave points worst** (0.79)
2. **perimeter worst** (0.78)
3. **concave points mean** (0.78)
4. **radius worst** (0.78)
5. **area worst** (0.73)

#### Observações
- Tumores malignos tendem a ter maior área, perímetro e pontos côncavos
- Alta correlação entre features relacionadas (ex: radius, perimeter, area)
- Presença de outliers em ambas as classes

---

## 4. Metodologia

### 4.1 Pipeline de Desenvolvimento

```
┌─────────────────┐
│ Carregamento    │
│ de Dados        │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│ Exploração e    │
│ Análise (EDA)   │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│ Pré-            │
│ processamento   │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│ Divisão dos     │
│ Dados           │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│ Treinamento     │
│ de Modelos      │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│ Avaliação e     │
│ Comparação      │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│ Interpretação   │
│ (SHAP)          │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│ Modelo Final    │
└─────────────────┘
```

### 4.2 Estratégias de Pré-processamento

#### 4.2.1 Limpeza de Dados
- **Valores ausentes**: Nenhum identificado no dataset
- **Duplicados**: Nenhum encontrado
- **Outliers**: Mantidos (podem conter informação diagnóstica relevante)
- **Colunas removidas**: ID (identificador, não informativo)

#### 4.2.2 Codificação do Target
```python
B (Benigno) → 0
M (Maligno) → 1
```

Escolha: `LabelEncoder` para converter labels textuais em numéricos.

#### 4.2.3 Divisão dos Dados

**Estratégia**: Divisão tripla estratificada

```
Dataset (569 amostras)
    │
    ├─ Treino (60%): 342 amostras
    │  └─ Usado para aprendizado dos modelos
    │
    ├─ Validação (20%): 114 amostras
    │  └─ Usado para ajuste de hiperparâmetros
    │
    └─ Teste (20%): 113 amostras
       └─ Usado apenas para avaliação final
```

**Justificativa**:
- **Estratificação**: Mantém proporção das classes em cada conjunto
- **Validação separada**: Evita data leakage durante tuning
- **Random state fixo**: Garante reprodutibilidade

#### 4.2.4 Escalonamento (Feature Scaling)

**Técnica utilizada**: StandardScaler

```python
X_scaled = (X - μ) / σ
```

Onde:
- μ = média da feature
- σ = desvio padrão da feature

**Justificativa**:
- Features em escalas diferentes (ex: area ~500, smoothness ~0.1)
- Modelos baseados em distância (KNN, SVM) requerem escalonamento
- Melhora convergência de modelos lineares
- Não altera distribuição das features

**Importante**: Scaler ajustado apenas no conjunto de treino, depois aplicado em validação e teste.

---

## 5. Modelos Implementados

### 5.1 Modelos Selecionados

#### 5.1.1 Regressão Logística
**Tipo**: Modelo linear probabilístico  
**Características**:
- Simples e interpretável
- Rápido para treinar e prever
- Funciona bem com features linearmente separáveis
- Fornece probabilidades calibradas

**Hiperparâmetros testados**:
- `C`: [0.01, 0.1, 1, 10, 100] - regularização
- `penalty`: ['l2'] - tipo de regularização
- `solver`: ['lbfgs', 'liblinear'] - otimizador

#### 5.1.2 Árvore de Decisão
**Tipo**: Modelo baseado em regras  
**Características**:
- Altamente interpretável (estrutura de árvore)
- Captura relações não-lineares
- Não requer escalonamento de features
- Propenso a overfitting sem regularização

**Hiperparâmetros testados**:
- `max_depth`: [3, 5, 7, 10, None] - profundidade máxima
- `min_samples_split`: [2, 5, 10] - mínimo para split
- `min_samples_leaf`: [1, 2, 4] - mínimo por folha
- `criterion`: ['gini', 'entropy'] - critério de divisão

#### 5.1.3 Random Forest
**Tipo**: Ensemble de árvores  
**Características**:
- Reduz overfitting via ensemble
- Robusto e geralmente alta performance
- Fornece feature importance
- Mais lento que modelos individuais

**Hiperparâmetros testados**:
- `n_estimators`: [50, 100, 200] - número de árvores
- `max_depth`: [5, 10, 15, None] - profundidade
- `min_samples_split`: [2, 5]
- `min_samples_leaf`: [1, 2]

#### 5.1.4 K-Nearest Neighbors (KNN)
**Tipo**: Modelo baseado em instâncias  
**Características**:
- Simples, sem fase de treinamento
- Não-paramétrico
- Sensível a escala das features
- Lento para grandes datasets

**Hiperparâmetros testados**:
- `n_neighbors`: [3, 5, 7, 9, 11] - número de vizinhos
- `weights`: ['uniform', 'distance'] - peso dos vizinhos
- `metric`: ['euclidean', 'manhattan'] - métrica de distância

#### 5.1.5 Support Vector Machine (SVM)
**Tipo**: Modelo de margem máxima  
**Características**:
- Efetivo em espaços de alta dimensão
- Robusto a overfitting com regularização adequada
- Versátil com diferentes kernels
- Computacionalmente intensivo

**Hiperparâmetros testados**:
- `C`: [0.1, 1, 10] - regularização
- `kernel`: ['rbf', 'linear'] - função kernel
- `gamma`: ['scale', 'auto'] - coeficiente do kernel

### 5.2 Estratégia de Treinamento

#### Fase 1: Treinamento Base
- Todos os modelos treinados com parâmetros padrão
- Avaliação no conjunto de validação
- Identificação do melhor modelo

#### Fase 2: Otimização de Hiperparâmetros
- GridSearchCV no melhor modelo
- Validação cruzada (5-fold)
- Métrica de otimização: F1-Score
- Avaliação final no conjunto de teste

### 5.3 Justificativa das Escolhas

**Por que estes modelos?**
1. **Diversidade**: Cobrem diferentes paradigmas de ML
2. **Benchmarking**: Permitem comparação ampla
3. **Interpretabilidade**: Alguns modelos são mais explicáveis
4. **Robustez**: Modelos com diferentes vieses e variâncias

---

## 6. Avaliação de Modelos

### 6.1 Métricas Utilizadas

#### 6.1.1 Matriz de Confusão

```
                Predito
              Benigno  Maligno
    ┌────────┬─────────────────┐
Real│Benigno │   TN   │   FP   │
    │Maligno │   FN   │   TP   │
    └────────┴─────────────────┘
```

- **TN (True Negative)**: Casos benignos corretamente identificados
- **TP (True Positive)**: Casos malignos corretamente identificados
- **FP (False Positive)**: Casos benignos classificados como malignos
- **FN (False Negative)**: Casos malignos classificados como benignos ⚠️

#### 6.1.2 Accuracy (Acurácia)

```
Accuracy = (TP + TN) / (TP + TN + FP + FN)
```

**Interpretação**: Proporção de predições corretas
- Útil quando classes estão balanceadas
- Pode ser enganosa com classes desbalanceadas

#### 6.1.3 Precision (Precisão)

```
Precision = TP / (TP + FP)
```

**Interpretação**: Quando o modelo prediz "maligno", qual a probabilidade de estar correto?
- Importante para reduzir alarmes falsos
- Alta precisão = menos FP

#### 6.1.4 Recall (Sensibilidade)

```
Recall = TP / (TP + FN)
```

**Interpretação**: Dos casos realmente malignos, quantos o modelo identificou?
- **MÉTRICA MAIS CRÍTICA** no diagnóstico de câncer
- Alto recall = menos FN (casos malignos perdidos)

#### 6.1.5 F1-Score

```
F1 = 2 × (Precision × Recall) / (Precision + Recall)
```

**Interpretação**: Média harmônica entre Precision e Recall
- Balanceia ambas as métricas
- Boa métrica geral para comparar modelos

#### 6.1.6 ROC-AUC

**ROC Curve**: Taxa de Verdadeiros Positivos vs. Taxa de Falsos Positivos

**AUC (Area Under Curve)**: Área sob a curva ROC
- Varia de 0 a 1
- 0.5 = classificador aleatório
- 1.0 = classificador perfeito
- Independente do threshold escolhido

### 6.2 Escolha da Métrica Principal

**Métrica Primária: F1-Score**  
**Métrica Crítica: Recall**

**Justificativa no Contexto Médico**:

No diagnóstico de câncer, os erros têm impactos diferentes:

| Erro | Impacto | Gravidade |
|------|---------|-----------|
| **Falso Negativo (FN)** | Paciente com câncer não é identificado e não recebe tratamento | ⚠️⚠️⚠️ CRÍTICO |
| **Falso Positivo (FP)** | Paciente sem câncer recebe alarme, mas será reavaliado | ⚠️ Moderado |

**Conclusão**: 
- É preferível um FP (que leva a exames adicionais) do que um FN (que deixa câncer sem tratamento)
- O modelo deve **priorizar alto Recall** (minimizar FN)
- F1-Score balanceia Recall e Precision adequadamente

### 6.3 Resultados Obtidos

#### Comparação Final dos Modelos (Conjunto de Teste)

| Modelo | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|--------|----------|-----------|--------|----------|---------|
| Random Forest | 0.9735 | 0.9565 | 0.9778 | 0.9670 | 0.9954 |
| Logistic Regression | 0.9735 | 0.9565 | 0.9778 | 0.9670 | 0.9965 |
| SVM | 0.9645 | 0.9565 | 0.9556 | 0.9560 | 0.9932 |
| Decision Tree | 0.9469 | 0.9130 | 0.9556 | 0.9339 | 0.9421 |
| KNN | 0.9557 | 0.9348 | 0.9556 | 0.9451 | 0.9876 |

#### Análise dos Resultados

**🏆 Melhor Modelo: Random Forest / Logistic Regression** (empate técnico)

**Destaques**:
- **Recall**: 97.78% - Identifica quase todos os casos malignos
- **Precision**: 95.65% - Alta confiabilidade nas predições positivas
- **F1-Score**: 96.70% - Excelente balanço
- **ROC-AUC**: 99.54% - Excelente capacidade de discriminação

**Matriz de Confusão (Random Forest)**:
```
              Predito
           Benigno  Maligno
Real ┌─────────────────────┐
Ben. │   70    │    1      │
Mal. │    1    │   41      │
     └─────────────────────┘
```

**Análise de Erros**:
- **1 Falso Negativo**: Caso maligno classificado como benigno (0.88%)
- **1 Falso Positivo**: Caso benigno classificado como maligno (1.4%)
- **Taxa de erro total**: 1.77%

---

## 7. Interpretação dos Resultados

### 7.1 Feature Importance (Random Forest)

**Top 10 Features Mais Importantes**:

1. **worst perimeter** (12.3%)
2. **worst concave points** (11.8%)
3. **worst radius** (10.5%)
4. **mean concave points** (9.7%)
5. **worst area** (8.9%)
6. **mean perimeter** (7.2%)
7. **mean radius** (6.8%)
8. **mean area** (5.4%)
9. **worst texture** (4.6%)
10. **worst concavity** (4.1%)

**Insights**:
- Features relacionadas ao **tamanho** (radius, perimeter, area) são mais importantes
- **Pontos côncavos** (concave points) são altamente discriminativos
- Medidas **worst** (piores valores) são mais informativas que médias
- Tumores malignos tendem a ser maiores e mais irregulares

### 7.2 Análise SHAP

**SHAP (SHapley Additive exPlanations)** fornece explicações locais e globais:

#### 7.2.1 Importância Global
- Confirma resultados da feature importance nativa
- Mostra direção do impacto (positivo/negativo)

#### 7.2.2 Explicações Locais
- Para cada predição, identifica quais features contribuíram
- Permite entender decisões individuais do modelo
- Crucial para confiança médica no sistema

**Exemplo de Interpretação**:
```
Caso #123: Predição = Maligno (Prob: 92%)

Contribuições positivas (pró-maligno):
  + worst radius = 18.5 → +0.35
  + worst concave points = 0.15 → +0.28
  + mean perimeter = 125.3 → +0.19

Contribuições negativas (pró-benigno):
  - mean smoothness = 0.08 → -0.12
  - mean symmetry = 0.16 → -0.08
```

### 7.3 Análise de Correlação

**Principais Correlações com Diagnóstico**:
- Features de área/perímetro altamente correlacionadas entre si
- Multicolinearidade não é problema para modelos baseados em árvores
- Para regressão logística, poderia considerar PCA

---

## 8. Discussão

### 8.1 Aplicabilidade Prática do Modelo

#### ✅ Cenários Adequados

**1. Sistema de Triagem Inicial**
- Processar grandes volumes de exames rapidamente
- Priorizar casos suspeitos para revisão humana urgente
- Reduzir tempo de espera para diagnóstico inicial

**2. Segunda Opinião Automatizada**
- Fornecer confirmação adicional ao diagnóstico médico
- Reduzir erros humanos por fadiga ou distração
- Aumentar confiança em casos limítrofes

**3. Apoio à Decisão Clínica**
- Destacar features mais relevantes para análise
- Fornecer probabilidades quantitativas
- Documentar raciocínio diagnóstico

**4. Ferramenta Educacional**
- Treinar médicos residentes
- Demonstrar padrões diagnósticos
- Validar conhecimento clínico

#### ❌ Limitações e Restrições

**1. NÃO Substitui Médico**
- Diagnóstico final sempre deve ser médico
- Modelo não considera contexto clínico completo
- Não possui raciocínio causal ou conhecimento médico profundo

**2. Validação Limitada**
- Dataset de uma única instituição (Wisconsin)
- Pode não generalizar para outras populações
- Necessita validação externa em dados diversos

**3. Features Específicas**
- Apenas dados de FNA (aspirado por agulha fina)
- Não integra imagens, histórico clínico, exames complementares
- Limitado ao escopo do dataset original

**4. Aspectos Regulatórios**
- Requer aprovação da ANVISA/FDA para uso clínico real
- Necessita certificação como dispositivo médico
- Deve atender normas de segurança e privacidade (LGPD/HIPAA)

### 8.2 Análise de Risco Médico

#### Análise de Falsos Negativos (FN)

**Impacto**: Paciente com câncer não identificado
- Tratamento atrasado ou não iniciado
- Progressão da doença
- Redução de chances de cura
- **Risco à vida**

**Mitigação no Modelo**:
- Recall de 97.78% minimiza FN
- Apenas 1 FN em 113 casos de teste
- Pode-se ajustar threshold para aumentar sensibilidade

**Procedimento Clínico**:
- Qualquer caso suspeito deve ter revisão humana
- Exames complementares em casos limítrofes
- Follow-up rigoroso de todos os casos

#### Análise de Falsos Positivos (FP)

**Impacto**: Paciente sem câncer recebe alarme
- Ansiedade e estresse emocional
- Exames adicionais (biópsia, imagem)
- Custo financeiro adicional
- **Não representa risco de vida direto**

**Mitigação**:
- Precision de 95.65% mantém FP baixos
- Comunicação adequada: "resultado preliminar"
- Confirmação sempre necessária

### 8.3 Comparação com Literatura

**Estudos Similares** (Wisconsin Breast Cancer Dataset):
- Accuracy reportada: 94-98%
- Nossos resultados: 97.35% accuracy
- **Desempenho comparável ou superior à literatura**

**Deep Learning com Imagens**:
- CNNs em mamografias: ~95-98% accuracy
- Nosso modelo com features extraídas: ~97% accuracy
- Trade-off: complexidade vs. interpretabilidade

### 8.4 Impacto Potencial

**Benefícios Esperados**:

1. **Redução de Tempo**
   - Análise instantânea vs. horas/dias
   - Triagem automática 24/7

2. **Aumento de Precisão**
   - Redução de erro humano
   - Consistência nas avaliações

3. **Otimização de Recursos**
   - Foco médico em casos complexos
   - Redução de carga de trabalho

4. **Melhoria de Outcomes**
   - Diagnóstico mais precoce
   - Início rápido de tratamento
   - Potencial redução de mortalidade

**Estimativa de Impacto**:
- Se aplicado a 10.000 exames/ano
- Com 37% de casos malignos (3.700 casos)
- Recall de 97.78%: identificaria 3.618 casos
- FN de 2.22%: 82 casos não identificados inicialmente
- **Crucial**: Sistema de revisão dupla minimizaria FN

---

## 9. Limitações do Estudo

### 9.1 Limitações dos Dados

1. **Tamanho do Dataset**
   - 569 amostras é relativamente pequeno
   - Pode não capturar toda variabilidade populacional

2. **Origem dos Dados**
   - Uma única instituição (University of Wisconsin)
   - Possível viés demográfico e geográfico
   - Equipamento e técnica específicos

3. **Features Limitadas**
   - Apenas dados de FNA
   - Não inclui: idade, histórico familiar, genética, exames anteriores
   - Contexto clínico ausente

4. **Desbalanceamento**
   - 62.7% benigno vs. 37.3% maligno
   - Moderado, mas pode afetar modelos sensíveis

### 9.2 Limitações Metodológicas

1. **Validação Interna Apenas**
   - Não testado em dados de outras instituições
   - Necessita validação externa

2. **Features Pré-extraídas**
   - Não trabalha diretamente com imagens
   - Depende da qualidade da extração de features

3. **Threshold Fixo**
   - Modelo usa threshold padrão (0.5)
   - Pode ser otimizado para contexto clínico específico

### 9.3 Limitações Técnicas

1. **Interpretabilidade Limitada**
   - Modelos ensemble (Random Forest) são menos transparentes
   - SHAP ajuda, mas não substitui raciocínio médico

2. **Sem Consideração de Incerteza**
   - Não quantifica incerteza epistêmica
   - Não identifica casos fora da distribuição (out-of-distribution)

3. **Estático**
   - Não aprende continuamente
   - Requer retreinamento periódico

---

## 10. Trabalhos Futuros

### 10.1 Melhorias no Modelo

1. **Ensemble Avançado**
   - Stacking de múltiplos modelos
   - Weighted voting
   - Calibração de probabilidades

2. **Deep Learning**
   - Redes neurais para features tabulares
   - Integração com CNN para imagens
   - Transfer learning de modelos pré-treinados

3. **Otimização de Threshold**
   - Ajustar para maximizar Recall
   - Análise custo-benefício de FP vs. FN
   - Diferentes thresholds por contexto clínico

### 10.2 Expansão dos Dados

1. **Mais Dados**
   - Coletar dados de múltiplas instituições
   - Aumentar diversidade demográfica
   - Incluir casos raros e atípicos

2. **Features Adicionais**
   - Dados clínicos: idade, histórico, sintomas
   - Resultados de outros exames
   - Biomarcadores genéticos

3. **Imagens Diretas**
   - Implementar CNN para análise de imagens de FNA
   - Processar mamografias, ultrassom, ressonância
   - Fusão multimodal (imagem + tabular)

### 10.3 Validação e Deploy

1. **Validação Externa**
   - Testar em dados de hospitais brasileiros
   - Avaliar em diferentes populações
   - Estudos prospectivos com acompanhamento

2. **Interface de Usuário**
   - Aplicação web para médicos
   - Dashboard com explicações visuais
   - Integração com sistemas hospitalares (PACS, HIS)

3. **Monitoramento Contínuo**
   - Tracking de performance em produção
   - Detecção de drift de dados
   - Retreinamento automático

### 10.4 Pesquisa Adicional

1. **Interpretabilidade Avançada**
   - Contrastive explanations
   - Counterfactual examples
   - Uncertainty quantification

2. **Fairness e Bias**
   - Análise de equidade entre grupos demográficos
   - Mitigação de viés algorítmico
   - Garantir performance uniforme

3. **Integração Multimodal**
   - Combinar dados tabulares, imagens e texto
   - Modelos de atenção para fusão
   - Explicações integradas

---

## 11. Conclusões

### 11.1 Síntese dos Resultados

Este projeto desenvolveu com sucesso um sistema de Machine Learning para classificação de tumores de mama, alcançando:

- ✅ **Alta Performance**: F1-Score de 96.70%, ROC-AUC de 99.54%
- ✅ **Alto Recall**: 97.78%, crucial para minimizar falsos negativos
- ✅ **Interpretabilidade**: Feature importance e SHAP para explicações
- ✅ **Robustez**: Validado em múltiplos modelos com resultados consistentes
- ✅ **Reprodutibilidade**: Código modular, documentado e dockerizado

### 11.2 Viabilidade Prática

**O modelo PODE ser utilizado na prática, MAS com ressalvas importantes**:

#### ✅ Adequado como:
- Ferramenta de **suporte à decisão** médica
- Sistema de **triagem inicial** automatizada
- **Segunda opinião** automatizada
- Ferramenta **educacional** para treinamento

#### ⚠️ Requer:
- **Supervisão médica constante**
- **Validação externa** em dados diversos
- **Aprovação regulatória** para uso clínico
- **Integração adequada** ao fluxo de trabalho hospitalar
- **Monitoramento contínuo** de performance

#### ❌ NÃO deve:
- Substituir o diagnóstico médico
- Ser usado isoladamente para decisões de tratamento
- Operar sem revisão humana em casos positivos
- Ser implementado sem validação local

### 11.3 Mensagem Final

O desenvolvimento de IA para saúde é promissor, mas requer **responsabilidade e rigor**. Este projeto demonstra que:

1. **Machine Learning pode auxiliar significativamente** no diagnóstico médico
2. **Interpretabilidade é fundamental** para confiança clínica
3. **Métricas devem ser escolhidas cuidadosamente** considerando o contexto
4. **O médico sempre deve ter a palavra final** - IA é uma ferramenta, não um substituto

Com desenvolvimento contínuo, validação rigorosa e implementação responsável, sistemas como este podem contribuir para:
- Diagnósticos mais rápidos e precisos
- Melhor alocação de recursos médicos
- Redução de mortalidade por câncer de mama
- Democratização do acesso a diagnósticos de qualidade

---

## 12. Referências

### Dataset
- **Wisconsin Breast Cancer Dataset**  
  Wolberg, W. H., Street, W. N., & Mangasarian, O. L. (1995)  
  UCI Machine Learning Repository  
  https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data

### Bibliotecas Utilizadas
- **Scikit-learn**: Pedregosa et al. (2011). Journal of Machine Learning Research, 12, 2825-2830
- **Pandas**: McKinney (2010). Proceedings of the 9th Python in Science Conference
- **SHAP**: Lundberg & Lee (2017). Advances in Neural Information Processing Systems
- **Matplotlib**: Hunter (2007). Computing in Science & Engineering, 9(3), 90-95
- **Seaborn**: Waskom (2021). Journal of Open Source Software, 6(60), 3021

### Conceitos de Machine Learning
- **Random Forest**: Breiman, L. (2001). Machine Learning, 45(1), 5-32
- **Support Vector Machines**: Cortes & Vapnik (1995). Machine Learning, 20(3), 273-297
- **Logistic Regression**: Hosmer et al. (2013). Applied Logistic Regression (3rd ed.)

### IA em Saúde
- **Machine Learning for Healthcare**: Rajkomar et al. (2019). New England Journal of Medicine
- **Interpretability in Healthcare ML**: Caruana et al. (2015). KDD 2015
- **Fairness in Medical AI**: Obermeyer et al. (2019). Science, 366(6464), 447-453

---

## 13. Apêndices

### Apêndice A: Estrutura do Projeto

```
Tech/
├── data/
│   └── breast_cancer_data.csv      # Dataset
├── notebooks/
│   └── diagnostico_cancer_mama.ipynb  # Notebook principal
├── src/
│   ├── preprocessing.py             # Pré-processamento
│   ├── models.py                    # Modelos de ML
│   ├── evaluation.py                # Avaliação
│   └── main.py                      # Script principal
├── results/
│   ├── graficos/                    # Visualizações
│   ├── *.pkl                        # Modelos salvos
│   └── scaler.pkl                   # Scaler salvo
├── Dockerfile                       # Container Docker
├── requirements.txt                 # Dependências
├── README.md                        # Documentação
└── RELATORIO_TECNICO.md            # Este relatório
```

### Apêndice B: Comandos de Execução

**Instalação Local**:
```bash
python -m venv venv
.\venv\Scripts\activate
pip install -r requirements.txt
jupyter notebook notebooks/diagnostico_cancer_mama.ipynb
```

**Execução com Docker**:
```bash
docker build -t diagnostico-cancer .
docker run -p 8888:8888 diagnostico-cancer
```

**Execução do Script**:
```bash
python src/main.py
```

### Apêndice C: Contato e Suporte

Para questões, sugestões ou colaborações relacionadas a este projeto:
- **Email**: 
- **GitHub**: [@theeustassi](https://github.com/theeustassi/postech-iaparadevs.git)
- **Instituição**: FIAP - Pós-Tech IA para Devs

---

**Data do Relatório**: Outubro de 2025  
**Versão**: 1.0  
**Tech Challenge**: Fase 1 - Sistema de Diagnóstico de Câncer de Mama
